{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-16T08:30:14.134656Z","iopub.execute_input":"2023-03-16T08:30:14.135544Z","iopub.status.idle":"2023-03-16T08:30:17.462577Z","shell.execute_reply.started":"2023-03-16T08:30:14.135506Z","shell.execute_reply":"2023-03-16T08:30:17.461467Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from cityscapedataset import Dataset, CityScapeClasses\n##import the sdn network here\nfrom sdn_architecture import SDN, Supervised_CE_loss","metadata":{"execution":{"iopub.status.busy":"2023-03-16T08:30:17.464499Z","iopub.execute_input":"2023-03-16T08:30:17.465285Z","iopub.status.idle":"2023-03-16T08:30:18.446261Z","shell.execute_reply.started":"2023-03-16T08:30:17.465246Z","shell.execute_reply":"2023-03-16T08:30:18.444328Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"classes = CityScapeClasses().classes\nclasses","metadata":{"execution":{"iopub.status.busy":"2023-03-16T08:30:18.447673Z","iopub.execute_input":"2023-03-16T08:30:18.448026Z","iopub.status.idle":"2023-03-16T08:30:18.468986Z","shell.execute_reply.started":"2023-03-16T08:30:18.447989Z","shell.execute_reply":"2023-03-16T08:30:18.468076Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['road',\n 'sidewalk',\n 'building',\n 'fence',\n 'pedestrian-railing',\n 'pole',\n 'traffic-light',\n 'traffic-sign',\n 'tree',\n 'vegetation',\n 'sky',\n 'person',\n 'rider',\n 'car',\n 'truck',\n 'bus',\n 'train',\n 'motorcycle',\n 'bicycle',\n 'misc']"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n##test overfitting\ntds = Dataset('train', im_size=(512,1024))\nval_ds = Dataset('val', im_size=(512,1024), length=10)\n#for final training#######################################################################\n#tds = Dataset('train', im_size=(512,1024))\n#val_ds = Dataset('val', im_size=(512,1024), length=40)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T08:30:18.473981Z","iopub.execute_input":"2023-03-16T08:30:18.474676Z","iopub.status.idle":"2023-03-16T08:30:18.485014Z","shell.execute_reply.started":"2023-03-16T08:30:18.474642Z","shell.execute_reply":"2023-03-16T08:30:18.484074Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class GPUDL():\n    def __init__(self, dl):\n        self.dl = dl\n    def __iter__(self):\n        for xb, yb in self.dl:\n            yield xb.to(device, non_blocking=True),yb.to(device, non_blocking=True)\n    def __len__(self):\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T08:30:18.487860Z","iopub.execute_input":"2023-03-16T08:30:18.491652Z","iopub.status.idle":"2023-03-16T08:30:18.503952Z","shell.execute_reply.started":"2023-03-16T08:30:18.491615Z","shell.execute_reply":"2023-03-16T08:30:18.502658Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2023-03-16T08:30:18.509049Z","iopub.execute_input":"2023-03-16T08:30:18.510077Z","iopub.status.idle":"2023-03-16T08:30:18.518493Z","shell.execute_reply.started":"2023-03-16T08:30:18.510032Z","shell.execute_reply":"2023-03-16T08:30:18.517407Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from unet_utils import miou, pixelwiseacc","metadata":{"execution":{"iopub.status.busy":"2023-03-16T08:30:18.520884Z","iopub.execute_input":"2023-03-16T08:30:18.522036Z","iopub.status.idle":"2023-03-16T08:30:18.538636Z","shell.execute_reply.started":"2023-03-16T08:30:18.522000Z","shell.execute_reply":"2023-03-16T08:30:18.537819Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train(model, lr, batch_size, epochs, weight_decay, tds, val_ds):\n    optim = torch.optim.SGD(model.parameters(), lr, weight_decay=weight_decay, momentum=0.99)\n    ##import special loss function here#######################################################\n    loss_fn = Supervised_CE_loss()\n    #loss_fn = nn.CrossEntropyLoss()\n    \n    dl = GPUDL(torch.utils.data.DataLoader(tds, batch_size, shuffle=True, num_workers=2))\n    val_dl = GPUDL(torch.utils.data.DataLoader(val_ds, batch_size,num_workers=2))\n    \n    model.to(device)\n    \n    sched = torch.optim.lr_scheduler.OneCycleLR(optim, lr, epochs=epochs, steps_per_epoch=len(dl))\n    \n    losses = []\n    val_losses = []\n    mious = []\n    val_mious = []\n    paccs = []\n    val_paccs = []\n    for epoch in range(epochs):\n        begin = time.time()\n        losses.append([])\n        val_losses.append([])\n        mious.append([]) \n        val_mious.append([])\n        paccs.append([])\n        val_paccs.append([])\n        for xb, yb in dl:\n            final, preds1, preds2, preds3 = model(xb)\n            loss = loss_fn(final,preds1,preds2,preds3, yb)\n            #loss = loss_fn(preds3[2], yb)\n            optim.zero_grad()\n            loss.backward()\n            \n            nn.utils.clip_grad_value_(model.parameters(), 0.1)\n            optim.step()\n            sched.step()\n            \n            losses[epoch].append(loss.item())\n            mious[epoch].append(miou(preds3[2],yb))\n            paccs[epoch].append(pixelwiseacc(preds3[2],yb))\n            del(xb);del(yb);del(loss);\n            del(preds1);del(preds2);del(preds3);\n            del(final)\n            torch.cuda.empty_cache()\n        with torch.no_grad():\n            model.eval()\n            for val_xb, val_yb in val_dl:\n                val_final, val_preds1, val_preds2, val_preds3 = model(val_xb)\n                val_loss = loss_fn(val_final, val_preds1, val_preds2, val_preds3, val_yb)\n                #val_loss = loss_fn(val_preds3[2], val_yb)\n                val_losses[epoch].append(val_loss.item())\n                val_mious[epoch].append(miou(val_preds3[2],val_yb))\n                val_paccs[epoch].append(pixelwiseacc(val_preds3[2],val_yb))\n                del(val_xb);del(val_yb);del(val_loss);\n                del(val_preds1);del(val_preds2);del(val_preds3)\n                del(val_final)\n                torch.cuda.empty_cache()\n            model.train()\n            with open(f'../working/SDN_{epoch+1}cepochsCityScapes.pt', 'wb') as f:\n                pass\n            torch.save(model.state_dict(), f'../working/SDN_{epoch+1}cepochsCityScapes.pt')\n        print('Epoch:', epoch + 1, 'TrainLoss:', f'{np.mean(losses[epoch]):.4f}', 'TMiou',f'{np.mean(mious[epoch]):.4f}', 'TPacc', f'{np.mean(paccs[epoch]):.4f}') \n        print('ValLoss', f'{np.mean(val_losses[epoch]):.4f},','VMiou',f'{np.mean(val_mious[epoch]):.4f}', 'VPacc', f'{np.mean(val_paccs[epoch]):.4f}',\n              f'{((time.time() - begin) / 60):.2f}', 'minutes')\n    return losses, val_losses","metadata":{"execution":{"iopub.status.busy":"2023-03-16T08:30:18.540291Z","iopub.execute_input":"2023-03-16T08:30:18.541023Z","iopub.status.idle":"2023-03-16T08:30:18.560365Z","shell.execute_reply.started":"2023-03-16T08:30:18.540987Z","shell.execute_reply":"2023-03-16T08:30:18.559401Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"##make sdn model object\nmodel = SDN(no_deconv=True, pretrained=False)\nmodel.load_state_dict(torch.load('/kaggle/input/38vmiousdn/SDN_3epochsCityScapes37VMIOU93PACC.pt'))\nmodel.train()\npass","metadata":{"execution":{"iopub.status.busy":"2023-03-16T08:30:18.562012Z","iopub.execute_input":"2023-03-16T08:30:18.562891Z","iopub.status.idle":"2023-03-16T08:30:31.513904Z","shell.execute_reply.started":"2023-03-16T08:30:18.562846Z","shell.execute_reply":"2023-03-16T08:30:31.512454Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"##hyperparams\nlr = 0.0002\nbatch_size = 1\nepochs = 10\nweight_decay = 0.000005","metadata":{"execution":{"iopub.status.busy":"2023-03-16T08:30:31.521773Z","iopub.execute_input":"2023-03-16T08:30:31.522247Z","iopub.status.idle":"2023-03-16T08:30:31.532125Z","shell.execute_reply.started":"2023-03-16T08:30:31.522206Z","shell.execute_reply":"2023-03-16T08:30:31.530890Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"losses, val_losses = train(model, lr, batch_size, epochs, weight_decay, tds, val_ds)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T08:30:31.537154Z","iopub.execute_input":"2023-03-16T08:30:31.539933Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch: 1 TrainLoss: 1.5251 TMiou 0.3662 TPacc 0.9187\nValLoss 1.3795, VMiou 0.3697 VPacc 0.9240 80.90 minutes\nEpoch: 2 TrainLoss: 1.5542 TMiou 0.3648 TPacc 0.9162\nValLoss 1.3929, VMiou 0.3689 VPacc 0.9273 81.33 minutes\nEpoch: 3 TrainLoss: 1.4766 TMiou 0.3693 TPacc 0.9202\nValLoss 1.3269, VMiou 0.3771 VPacc 0.9314 81.51 minutes\nEpoch: 4 TrainLoss: 1.3389 TMiou 0.3772 TPacc 0.9278\nValLoss 1.3010, VMiou 0.3736 VPacc 0.9308 80.71 minutes\nEpoch: 5 TrainLoss: 1.2030 TMiou 0.3862 TPacc 0.9353\nValLoss 1.3858, VMiou 0.3833 VPacc 0.9319 80.85 minutes\nEpoch: 6 TrainLoss: 1.0964 TMiou 0.3943 TPacc 0.9408\nValLoss 1.2783, VMiou 0.3844 VPacc 0.9339 80.87 minutes\nEpoch: 7 TrainLoss: 1.0077 TMiou 0.4017 TPacc 0.9455\nValLoss 1.2753, VMiou 0.3863 VPacc 0.9338 80.76 minutes\nEpoch: 8 TrainLoss: 0.9389 TMiou 0.4082 TPacc 0.9491\nValLoss 1.2405, VMiou 0.3951 VPacc 0.9367 81.07 minutes\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(losses[0], val_losses[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../working/SDN_FINALepochsCityScapes.pt', 'wb') as f:\n    pass\ntorch.save(model.state_dict(), '../working/SDN_1epochsCityScapes.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction on Dataset","metadata":{}},{"cell_type":"code","source":"##to test overfitting\nimg, label = tds[0]\n\n##to test actual accuracy on validation\n#img, label = val_ds[12]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(img.permute(1,2,0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ground Truth Value","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(label, cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction indices visualized","metadata":{}},{"cell_type":"code","source":"final, pred1, pred2, pred3 = model(img.to(device).reshape(-1,3,512,1024))#[0][2].reshape(20,512,1024)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asdf, idxs = torch.max(pred1[0].reshape(20,512,1024), dim=0)\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(idxs.cpu(), cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asdf, idxs = torch.max(pred1[1].reshape(20,512,1024), dim=0)\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(idxs.cpu(), cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asdf, idxs = torch.max(pred1[2].reshape(20,512,1024), dim=0)\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(idxs.cpu(), cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asdf, idxs = torch.max(pred2[0].reshape(20,512,1024), dim=0)\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(idxs.cpu(), cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asdf, idxs = torch.max(pred2[1].reshape(20,512,1024), dim=0)\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(idxs.cpu(), cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asdf, idxs = torch.max(pred2[2].reshape(20,512,1024), dim=0)\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(idxs.cpu(), cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asdf, idxs = torch.max(pred3[0].reshape(20,512,1024), dim=0)\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(idxs.cpu(), cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asdf, idxs = torch.max(pred3[1].reshape(20,512,1024), dim=0)\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(idxs.cpu(), cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asdf, idxs = torch.max(pred3[2].reshape(20,512,1024), dim=0)\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(idxs.cpu(), cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asdf, idxs = torch.max(final.reshape(20,512,1024), dim=0)\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot()\nax.imshow(idxs.cpu(), cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction on Valildation Data","metadata":{}},{"cell_type":"code","source":"colorify(idxs.cpu(), (512,1024))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def colorify(idxs, img_shape, figsize=(20,20)):\n    idxs = np.array(idxs.to('cpu'))\n    assert img_shape[0] == idxs.shape[0] and img_shape[1] == idxs.shape[1]\n                          ##road         ##sidelwalk    building        fence       p-railing       pole      traffic-light\n    colors = np.array([[162, 75, 175], [244,31,181], [113,103,112], [100,75,44], [147,98,39], [203,202,190], [219,169,42],\n                 [255,246,69], [21,149,18], [155,243,154], [39,201,200], [234,22,47], [255,0,30], [39,62,163]])\n                   #traffic-sign    ##tree       vegetation       sky         person       rider         car\n    colors = np.append(colors, ([[78,105,221], [128,147,224], [82,96,159], [94,19,36], [123,48,66], [0,0,0]]))\n                                   #truck           bus           train       motorcycle   bicycle     misc\n    colors = colors.reshape((20,3))\n    \n    \n    cmap = torch.zeros((3,img_shape[0], img_shape[1])).long()\n    \n    for i in range(len(colors)):\n        cmap[0,idxs==i] = colors[i][0]\n        cmap[1,idxs==i] = colors[i][1]\n        cmap[2,idxs==i] = colors[i][2]\n    \n    fig = plt.figure(figsize=(figsize[0], figsize[1]))\n    ax = fig.add_subplot()\n    ax.imshow(cmap.permute(1,2,0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}